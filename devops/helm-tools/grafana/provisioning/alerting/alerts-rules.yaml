apiVersion: 1

groups:
  # =========================
  # AKS (Prometheus)
  # =========================
  - name: AKS Nodes
    folder: Infrastructure
    interval: 1m
    rules:
      - uid: node-notready
        title: "AKS Node NotReady"
        condition: B
        data:
          - refId: A
            datasourceUid: prometheus
            queryType: ''
            relativeTimeRange: { from: 300, to: 0 }
            model:
              expr: 'kube_node_status_condition{condition="Ready",status="false"}'
              refId: A
              intervalMs: 1000
              maxDataPoints: 43200
          - refId: B
            datasourceUid: __expr__
            queryType: ''
            relativeTimeRange: { from: 300, to: 0 }
            model:
              type: reduce
              expression: A
              reducer: last
              settings: { mode: replaceNN, replaceWithValue: 0 }
              refId: B
          - refId: C
            datasourceUid: __expr__
            queryType: ''
            relativeTimeRange: { from: 300, to: 0 }
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator: { type: gt, params: [0] }
                  operator: { type: and }
                  query: { params: [C] }
              refId: C
        noDataState: OK
        execErrState: Alerting
        for: 1m
        annotations:
          summary: "Node {{ $labels.node }} is NotReady"
          description: "Node {{ $labels.node }} has been in NotReady state for more than 1 minute"
        labels: { severity: critical }

  - name: AKS Pod States
    folder: Infrastructure
    interval: 1m
    rules:
      - uid: pod-failure-state
        title: "Pod Failure State (stage/dev only)"
        condition: B
        data:
          - refId: A
            datasourceUid: prometheus
            queryType: ''
            relativeTimeRange: { from: 300, to: 0 }
            model:
              expr: |
                (
                  kube_pod_container_status_waiting_reason{reason=~"CrashLoopBackOff|ImagePullBackOff|ErrImagePull|CreateContainerError|StartError|CreateContainerConfigError|InvalidImageName", namespace=~"stage|dev", pod!~"app-stats-ping.*"}
                or
                  kube_pod_container_status_terminated_reason{reason=~"Error|StartError|OOMKilled|ContainerCannotRun", namespace=~"stage|dev", pod!~"app-stats-ping.*"}
                )
              refId: A
              intervalMs: 1000
              maxDataPoints: 43200
          - refId: B
            datasourceUid: __expr__
            queryType: ''
            relativeTimeRange: { from: 300, to: 0 }
            model:
              type: reduce
              expression: A
              reducer: last
              settings: { mode: replaceNN, replaceWithValue: 0 }
              refId: B
          - refId: C
            datasourceUid: __expr__
            queryType: ''
            relativeTimeRange: { from: 300, to: 0 }
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator: { type: gt, params: [0] }
                  operator: { type: and }
                  query: { params: [C] }
              refId: C
        noDataState: OK
        execErrState: Alerting
        for: 1m
        annotations:
          summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} failure detected"
          description: |
            Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} is failing.
            Reason: {{ $labels.reason }}
        labels: { severity: warning }

  - name: AKS Memory Usage
    folder: Infrastructure
    interval: 1m
    rules:
      - uid: pod-high-memory
        title: "Pod High Memory Usage"
        condition: B
        data:
          - refId: A
            datasourceUid: prometheus
            queryType: ''
            relativeTimeRange: { from: 300, to: 0 }
            model:
              expr: |
                (
                  sum by (namespace, pod) (container_memory_usage_bytes{container!=""})
                  /
                  sum by (namespace, pod) (container_spec_memory_limit_bytes{container!=""})
                ) * 100
              refId: A
              intervalMs: 1000
              maxDataPoints: 43200
          - refId: B
            datasourceUid: __expr__
            model:
              type: threshold
              expression: A
              conditions:
                - evaluator: { type: gt, params: [90] }
                  operator: { type: and }
                  query: { params: [B] }
              refId: B
        noDataState: OK
        execErrState: Alerting
        for: 2m
        annotations:
          summary: "High Memory Usage in Pod {{ $labels.namespace }}/{{ $labels.pod }}"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is using more than 90% of its memory limit."
        labels: { severity: warning }

  # =========================
  # Frontend (App Insights via Log Analytics)
  # =========================
  - name: Frontend (App Insights Logs)
    folder: Infrastructure
    interval: 1m
    rules:

      # ---------- student ----------
      - uid: ai-student-failure
        title: "Frontend(student): Failure rate > 5%"
        condition: C
        data:
          - refId: A
            datasourceUid: azure-monitor
            relativeTimeRange: { from: 600, to: 0 }   # 10m lookback
            model:
              queryType: "Azure Log Analytics"
              resultFormat: time_series
              azureLogAnalytics:
                workspace: "${LA_WS_STUDENT}"      # Workspace Resource ID
              query: |
                requests
                | where TimeGenerated > ago(10m)
                | summarize total=count(), failed=countif(success==false) by bin(TimeGenerated, 1m)
                | extend failureRate = iff(total < 20, 0.0, 100.0 * todouble(failed) / todouble(total))
                | project TimeGenerated, failureRate
              refId: A
          - refId: B
            datasourceUid: __expr__
            model: { type: reduce, expression: A, reducer: last, settings: { mode: replaceNN, replaceWithValue: 0 } }
          - refId: C
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions: [ { evaluator: { type: gt, params: [5] }, operator: { type: and }, query: { params: [C] } } ]
        for: 5m
        noDataState: NoData
        execErrState: Error
        labels: { severity: critical, app: student }
        annotations: { summary: "High failure rate (student)" }

      - uid: ai-student-5xx
        title: "Frontend(student): 5xx% > 1%"
        condition: C
        data:
          - refId: A
            datasourceUid: azure-monitor
            relativeTimeRange: { from: 600, to: 0 }
            model:
              queryType: "Azure Log Analytics"
              resultFormat: time_series
              azureLogAnalytics:
                workspace: "${LA_WS_STUDENT}"
              query: |
                requests
                | where TimeGenerated > ago(10m)
                | summarize total=count(), fivexx=countif(toint(resultCode) between (500..599)) by bin(TimeGenerated, 1m)
                | extend pct_5xx = iff(total == 0, 0.0, 100.0 * todouble(fivexx) / todouble(total))
                | project TimeGenerated, pct_5xx
              refId: A
          - refId: B
            datasourceUid: __expr__
            model: { type: reduce, expression: A, reducer: last, settings: { mode: replaceNN, replaceWithValue: 0 } }
          - refId: C
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions: [ { evaluator: { type: gt, params: [1] }, operator: { type: and }, query: { params: [C] } } ]
        for: 5m
        noDataState: NoData
        execErrState: Error
        labels: { severity: critical, app: student }
        annotations: { summary: "5xx rate high (student)" }

      - uid: ai-student-p95
        title: "Frontend(student): p95 > 2000ms"
        condition: C
        data:
          - refId: A
            datasourceUid: azure-monitor
            relativeTimeRange: { from: 1200, to: 0 }   # 20m lookback
            model:
              queryType: "Azure Log Analytics"
              resultFormat: time_series
              azureLogAnalytics:
                workspace: "${LA_WS_STUDENT}"
              query: |
                requests
                | where TimeGenerated > ago(10m)
                | summarize p95_ms = toreal(percentile(duration, 95) / 1ms) by bin(TimeGenerated, 2m)
                | project TimeGenerated, p95_ms
              refId: A
          - refId: B
            datasourceUid: __expr__
            model: { type: reduce, expression: A, reducer: last, settings: { mode: replaceNN, replaceWithValue: 0 } }
          - refId: C
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions: [ { evaluator: { type: gt, params: [2000] }, operator: { type: and }, query: { params: [C] } } ]
        for: 10m
        noDataState: NoData
        execErrState: Error
        labels: { severity: warning, app: student }
        annotations: { summary: "Slow p95 latency (student)" }

      # ---------- admin ----------
      - uid: ai-admin-failure
        title: "Frontend(admin): Failure rate > 5%"
        condition: C
        data:
          - refId: A
            datasourceUid: azure-monitor
            relativeTimeRange: { from: 600, to: 0 }
            model:
              queryType: "Azure Log Analytics"
              resultFormat: time_series
              azureLogAnalytics:
                workspace: "${LA_WS_ADMIN}"
              query: |
                requests
                | where TimeGenerated > ago(10m)
                | summarize total=count(), failed=countif(success==false) by bin(TimeGenerated, 1m)
                | extend failureRate = iff(total < 20, 0.0, 100.0 * todouble(failed) / todouble(total))
                | project TimeGenerated, failureRate
              refId: A
          - refId: B
            datasourceUid: __expr__
            model: { type: reduce, expression: A, reducer: last, settings: { mode: replaceNN, replaceWithValue: 0 } }
          - refId: C
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions: [ { evaluator: { type: gt, params: [5] }, operator: { type: and }, query: { params: [C] } } ]
        for: 5m
        noDataState: NoData
        execErrState: Error
        labels: { severity: critical, app: admin }
        annotations: { summary: "High failure rate (admin)" }

      - uid: ai-admin-5xx
        title: "Frontend(admin): 5xx% > 1%"
        condition: C
        data:
          - refId: A
            datasourceUid: azure-monitor
            relativeTimeRange: { from: 600, to: 0 }
            model:
              queryType: "Azure Log Analytics"
              resultFormat: time_series
              azureLogAnalytics:
                workspace: "${LA_WS_ADMIN}"
              query: |
                requests
                | where TimeGenerated > ago(10m)
                | summarize total=count(), fivexx=countif(toint(resultCode) between (500..599)) by bin(TimeGenerated, 1m)
                | extend pct_5xx = iff(total == 0, 0.0, 100.0 * todouble(fivexx) / todouble(total))
                | project TimeGenerated, pct_5xx
              refId: A
          - refId: B
            datasourceUid: __expr__
            model: { type: reduce, expression: A, reducer: last, settings: { mode: replaceNN, replaceWithValue: 0 } }
          - refId: C
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions: [ { evaluator: { type: gt, params: [1] }, operator: { type: and }, query: { params: [C] } } ]
        for: 5m
        noDataState: NoData
        execErrState: Error
        labels: { severity: critical, app: admin }
        annotations: { summary: "5xx rate high (admin)" }

      - uid: ai-admin-p95
        title: "Frontend(admin): p95 > 2000ms"
        condition: C
        data:
          - refId: A
            datasourceUid: azure-monitor
            relativeTimeRange: { from: 1200, to: 0 }
            model:
              queryType: "Azure Log Analytics"
              resultFormat: time_series
              azureLogAnalytics:
                workspace: "${LA_WS_ADMIN}"
              query: |
                requests
                | where TimeGenerated > ago(10m)
                | summarize p95_ms = toreal(percentile(duration, 95) / 1ms) by bin(TimeGenerated, 2m)
                | project TimeGenerated, p95_ms
              refId: A
          - refId: B
            datasourceUid: __expr__
            model: { type: reduce, expression: A, reducer: last, settings: { mode: replaceNN, replaceWithValue: 0 } }
          - refId: C
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions: [ { evaluator: { type: gt, params: [2000] }, operator: { type: and }, query: { params: [C] } } ]
        for: 10m
        noDataState: NoData
        execErrState: Error
        labels: { severity: warning, app: admin }
        annotations: { summary: "Slow p95 latency (admin)" }

      # ---------- teacher ----------
      - uid: ai-teacher-failure
        title: "Frontend(teacher): Failure rate > 5%"
        condition: C
        data:
          - refId: A
            datasourceUid: azure-monitor
            relativeTimeRange: { from: 600, to: 0 }
            model:
              queryType: "Azure Log Analytics"
              resultFormat: time_series
              azureLogAnalytics:
                workspace: "${LA_WS_TEACHER}"
              query: |
                requests
                | where TimeGenerated > ago(10m)
                | summarize total=count(), failed=countif(success==false) by bin(TimeGenerated, 1m)
                | extend failureRate = iff(total < 20, 0.0, 100.0 * todouble(failed) / todouble(total))
                | project TimeGenerated, failureRate
              refId: A
          - refId: B
            datasourceUid: __expr__
            model: { type: reduce, expression: A, reducer: last, settings: { mode: replaceNN, replaceWithValue: 0 } }
          - refId: C
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions: [ { evaluator: { type: gt, params: [5] }, operator: { type: and }, query: { params: [C] } } ]
        for: 5m
        noDataState: NoData
        execErrState: Error
        labels: { severity: critical, app: teacher }
        annotations: { summary: "High failure rate (teacher)" }

      - uid: ai-teacher-5xx
        title: "Frontend(teacher): 5xx% > 1%"
        condition: C
        data:
          - refId: A
            datasourceUid: azure-monitor
            relativeTimeRange: { from: 600, to: 0 }
            model:
              queryType: "Azure Log Analytics"
              resultFormat: time_series
              azureLogAnalytics:
                workspace: "${LA_WS_TEACHER}"
              query: |
                requests
                | where TimeGenerated > ago(10m)
                | summarize total=count(), fivexx=countif(toint(resultCode) between (500..599)) by bin(TimeGenerated, 1m)
                | extend pct_5xx = iff(total == 0, 0.0, 100.0 * todouble(fivexx) / todouble(total))
                | project TimeGenerated, pct_5xx
              refId: A
          - refId: B
            datasourceUid: __expr__
            model: { type: reduce, expression: A, reducer: last, settings: { mode: replaceNN, replaceWithValue: 0 } }
          - refId: C
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions: [ { evaluator: { type: gt, params: [1] }, operator: { type: and }, query: { params: [C] } } ]
        for: 5m
        noDataState: NoData
        execErrState: Error
        labels: { severity: critical, app: teacher }
        annotations: { summary: "5xx rate high (teacher)" }

      - uid: ai-teacher-p95
        title: "Frontend(teacher): p95 > 2000ms"
        condition: C
        data:
          - refId: A
            datasourceUid: azure-monitor
            relativeTimeRange: { from: 1200, to: 0 }
            model:
              queryType: "Azure Log Analytics"
              resultFormat: time_series
              azureLogAnalytics:
                workspace: "${LA_WS_TEACHER}"
              query: |
                requests
                | where TimeGenerated > ago(10m)
                | summarize p95_ms = toreal(percentile(duration, 95) / 1ms) by bin(TimeGenerated, 2m)
                | project TimeGenerated, p95_ms
              refId: A
          - refId: B
            datasourceUid: __expr__
            model: { type: reduce, expression: A, reducer: last, settings: { mode: replaceNN, replaceWithValue: 0 } }
          - refId: C
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions: [ { evaluator: { type: gt, params: [2000] }, operator: { type: and }, query: { params: [C] } } ]
        for: 10m
        noDataState: NoData
        execErrState: Error
        labels: { severity: warning, app: teacher }
        annotations: { summary: "Slow p95 latency (teacher)" }