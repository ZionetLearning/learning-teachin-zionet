name: AKS - Update Pod Containers

run-name: >
  🚢 Helm Deploy | Environment: ${{ 
    inputs.environment_name || github.event.inputs.environment_name || 'dev'
  }} | GitHub Env: ${{ inputs.environment || github.event.inputs.environment }}

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Select environment (GitHub Environment)'
        required: true
        default: 'Development'
        type: choice
        options: [Development, Production]
      environment_name:
        description: 'Optional namespace/prefix (lowercase letters & digits). Empty -> dev'
        required: false
        default: ''
      image_tag:
        description: 'Optional image tag (e.g., commit hash). Empty -> uses environment_name'
        required: false
        default: ''

  workflow_call:
    inputs:
      environment:
        required: true
        type: string
      environment_name:
        required: false
        type: string
      image_tag:
        required: false
        type: string
        description: 'Docker image tag to deploy (e.g., commit hash)'
      skip_infra_steps:
        required: false
        type: boolean
        default: false
    outputs:
      app_url:
        description: "Ingress URL (if already created by platform setup)"
        value: ${{ jobs.deploy.outputs.app_url }}

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment || github.event.inputs.environment }}
    permissions:
      id-token: write
      contents: read

    outputs:
      app_url: ${{ steps.extract_url.outputs.app_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login via OIDC
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Set up variables
        id: setup
        run: |
          ENVIRONMENT_NAME="${{ inputs.environment_name || github.event.inputs.environment_name }}"
          if [ -n "$ENVIRONMENT_NAME" ]; then
            [[ "$ENVIRONMENT_NAME" =~ ^[a-z0-9]+$ ]] || { echo "environment_name must be ^[a-z0-9]+$"; exit 1; }
            echo "TARGET_NAMESPACE=$ENVIRONMENT_NAME" >> $GITHUB_ENV
            echo "RESOLVED_TARGET=custom($ENVIRONMENT_NAME)" >> $GITHUB_ENV
          else
            echo "TARGET_NAMESPACE=dev" >> $GITHUB_ENV
            echo "RESOLVED_TARGET=dev" >> $GITHUB_ENV
          fi

          echo "K8S_DIR=devops/kubernetes/" >> $GITHUB_ENV
          echo "CHART_DIR=devops/kubernetes/charts" >> $GITHUB_ENV
          echo "VALUES_FILE=devops/kubernetes/charts/values.dev.yaml" >> $GITHUB_ENV
          echo "ACR_NAME=teachindevacr" >> $GITHUB_ENV
          echo "ACR_LOGIN_SERVER=teachindevacr.azurecr.io" >> $GITHUB_ENV

          # Shared AKS
          echo "AKS_RG=dev-zionet-learning-2025" >> $GITHUB_ENV
          echo "AKS_NAME=aks-cluster-dev" >> $GITHUB_ENV

          # PG (shared)
          echo "PG_DB=dev-pg-zionet-learning" >> $GITHUB_ENV
          echo "PG_RG=dev-zionet-learning-2025" >> $GITHUB_ENV


          # Determine if infrastructure steps should be skipped
          # Skip for: push events (auto PR merge) OR manual dispatch (no skip_infra_steps input) OR when skip_infra_steps=true
          # Run for: CI/CD workflows (when skip_infra_steps is explicitly false)
          if [[ "${{ github.event_name }}" == "push" ]]; then
            echo "Push event detected, skipping infrastructure"
            echo "skip_infra_steps=true" >> $GITHUB_OUTPUT
          elif [ "${{ inputs.skip_infra_steps }}" = "" ]; then
            echo "Manual dispatch - no skip_infra_steps input, skipping infrastructure"
            echo "skip_infra_steps=true" >> $GITHUB_OUTPUT
          elif [ "${{ inputs.skip_infra_steps }}" = "true" ]; then
            echo "skip_infra_steps=true passed, skipping infrastructure"
            echo "skip_infra_steps=true" >> $GITHUB_OUTPUT
          else
            echo "skip_infra_steps=false passed, running infrastructure"
            echo "skip_infra_steps=false" >> $GITHUB_OUTPUT
          fi

          # Redis (shared)
          case "$ENVIRONMENT_NAME" in
            dev)
              echo "REDIS_DATABASE_INDEX=0" >> $GITHUB_ENV
              ;;
            prod)
              echo "REDIS_DATABASE_INDEX=1" >> $GITHUB_ENV
              ;;
            test)
              echo "REDIS_DATABASE_INDEX=2" >> $GITHUB_ENV
              ;;
            featest)
              echo "REDIS_DATABASE_INDEX=3" >> $GITHUB_ENV
              ;;
            featest2)
              echo "REDIS_DATABASE_INDEX=4" >> $GITHUB_ENV
              ;;
            *)
              echo "REDIS_DATABASE_INDEX=5" >> $GITHUB_ENV
              echo "ENVIRONMENT_NAME is $ENVIRONMENT_NAME"
              ;;
          esac

          # Key Vault access for other secrets (not Service Bus)
          echo "KEYVAULT_CLIENT_ID=${{ secrets.KEYVAULT_CLIENT_ID }}" >> $GITHUB_ENV
          echo "KEYVAULT_TENANT_ID=${{ secrets.KEYVAULT_TENANT_ID }}" >> $GITHUB_ENV
          
          # Service Bus Managed Identity (from Terraform outputs)
          # Use ENVIRONMENT_NAME directly since TARGET_NAMESPACE env var isn't available in same step
          CURRENT_NAMESPACE="${ENVIRONMENT_NAME:-dev}"
          echo "SERVICEBUS_NAMESPACE=${CURRENT_NAMESPACE}-servicebus-zionet-learning.servicebus.windows.net" >> $GITHUB_ENV
          
          # Get managed identity client ID from the resource group
          MANAGED_IDENTITY_CLIENT_ID=$(az identity show \
            --resource-group "${CURRENT_NAMESPACE}-zionet-learning-2025" \
            --name "${CURRENT_NAMESPACE}-app-identity" \
            --query clientId -o tsv 2>/dev/null)
          if [ -z "$MANAGED_IDENTITY_CLIENT_ID" ]; then
            echo "WARNING: Managed identity not found for namespace '${CURRENT_NAMESPACE}'. Falling back to KEYVAULT_CLIENT_ID." >&2
            MANAGED_IDENTITY_CLIENT_ID="${{ secrets.KEYVAULT_CLIENT_ID }}"
          fi
          echo "SERVICEBUS_CLIENT_ID=$MANAGED_IDENTITY_CLIENT_ID" >> $GITHUB_ENV
          
          # SignalR Managed Identity (from Terraform outputs)
          echo "SIGNALR_ENDPOINT=https://${CURRENT_NAMESPACE}-signalr-teachin.service.signalr.net" >> $GITHUB_ENV
          echo "SIGNALR_CLIENT_ID=$MANAGED_IDENTITY_CLIENT_ID" >> $GITHUB_ENV
          
          # PostgreSQL Managed Identity (from Terraform outputs)
          echo "POSTGRES_ENDPOINT=Host=dev-pg-zionet-learning.postgres.database.azure.com;Database=appdb-${CURRENT_NAMESPACE};Username=${CURRENT_NAMESPACE}-app-identity@dev-pg-zionet-learning" >> $GITHUB_ENV
          echo "POSTGRES_CLIENT_ID=$MANAGED_IDENTITY_CLIENT_ID" >> $GITHUB_ENV
          
      - name: Get AKS credentials
        run: az aks get-credentials --resource-group $AKS_RG --name $AKS_NAME --overwrite-existing

      - name: Create namespace
        if: ${{ steps.setup.outputs.skip_infra_steps == 'false' }}
        run: |
          kubectl create namespace "$TARGET_NAMESPACE" --dry-run=client -o yaml | kubectl apply -f -

      - name: Check and fix Helm release status
        run: |
          echo "Checking Helm release status for namespace: $TARGET_NAMESPACE"
          RELEASE_STATUS=$(helm status app -n "$TARGET_NAMESPACE" -o json 2>/dev/null | jq -r '.info.status' || echo "not-found")
          echo "Current release status: $RELEASE_STATUS"

          if [[ "$RELEASE_STATUS" == "pending-install" ]] || [[ "$RELEASE_STATUS" == "pending-upgrade" ]] || [[ "$RELEASE_STATUS" == "pending-rollback" ]]; then
            echo "Found pending operation. Attempting rollback..."
            helm rollback app -n "$TARGET_NAMESPACE" || echo "Rollback failed, trying to delete release history..."
            helm delete app -n "$TARGET_NAMESPACE" --wait || echo "Delete failed, continuing anyway..."
            sleep 5
          fi

          echo "Helm release status check complete."

      - name: Wait for external IP for ingress controller
        if: ${{ steps.setup.outputs.skip_infra_steps == 'false' }}
        run: |
          echo "Waiting for external IP for ingress-nginx-controller..."
          for i in {1..30}; do
            INGRESS_IP=$(kubectl -n devops-ingress-nginx get svc ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
            if [[ -n "$INGRESS_IP" ]]; then
              echo "Ingress IP is ready: $INGRESS_IP"
              echo "ingress_url=http://$INGRESS_IP" >> $GITHUB_OUTPUT
              exit 0
            fi
            echo "Attempt $i: not ready. Sleeping 10s..."
            sleep 10
          done
          echo "Failed to get ingress IP."; exit 1

      - name: Add ingress IP to PostgreSQL firewall
        if: ${{ steps.setup.outputs.skip_infra_steps == 'false' }}
        run: |
          INGRESS_IP=$(kubectl -n devops-ingress-nginx get svc ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          az postgres flexible-server firewall-rule create \
            --resource-group $PG_RG \
            --name $PG_DB \
            --rule-name allow-ingress-controller \
            --start-ip-address $INGRESS_IP \
            --end-ip-address $INGRESS_IP

      - name: Add AKS outbound IP to PostgreSQL firewall
        if: ${{ steps.setup.outputs.skip_infra_steps == 'false' }}
        run: |
          # Try NAT Gateway first, else fallback to Load Balancer
          OUTBOUND_IP_ID=$(az aks show \
            --resource-group $AKS_RG \
            --name $AKS_NAME \
            --query "networkProfile.natGatewayProfile.effectiveOutboundIPs[0].id" -o tsv 2>/dev/null || true)

          if [ -z "$OUTBOUND_IP_ID" ] || [ "$OUTBOUND_IP_ID" = "null" ]; then
            echo "No NAT Gateway found, checking Load Balancer outbound IP..."
            OUTBOUND_IP_ID=$(az aks show \
              --resource-group $AKS_RG \
              --name $AKS_NAME \
              --query "networkProfile.loadBalancerProfile.effectiveOutboundIPs[0].id" -o tsv)
          fi

          if [ -z "$OUTBOUND_IP_ID" ] || [ "$OUTBOUND_IP_ID" = "null" ]; then
            echo "Could not detect outbound IP ID for AKS cluster."
            exit 1
          fi

          AKS_EGRESS_IP=$(az resource show --ids $OUTBOUND_IP_ID --query "properties.ipAddress" -o tsv)

          echo "AKS outbound IP: $AKS_EGRESS_IP"

          az postgres flexible-server firewall-rule create \
            --resource-group $PG_RG \
            --name $PG_DB \
            --rule-name allow-aks-egress \
            --start-ip-address $AKS_EGRESS_IP \
            --end-ip-address $AKS_EGRESS_IP
            

      - name: Install External Secrets Operator (with CRDs)
        if: ${{ steps.setup.outputs.skip_infra_steps == 'false' }}
        run: |
          helm repo add external-secrets https://charts.external-secrets.io
          helm repo update
          helm upgrade --install external-secrets external-secrets/external-secrets \
            --namespace external-secrets \
            --create-namespace \
            --set installCRDs=true \
            --wait --timeout 180s

      - name: Wait for External Secrets API
        if: ${{ steps.setup.outputs.skip_infra_steps == 'false' }}
        run: |
          echo "⏳ Waiting for ExternalSecrets API..."
          for i in {1..30}; do
            if kubectl api-resources | grep -q "externalsecrets"; then
              echo "✅ ExternalSecrets API ready"
              exit 0
            fi
            echo "Waiting for API..."
            sleep 5
          done
          echo "❌ Timeout waiting for ExternalSecrets API"
          exit 1

      - name: Helm template sanity (no Namespace objects)
        run: |
          # Use image_tag if provided, otherwise fall back to TARGET_NAMESPACE
          IMAGE_TAG="${{ inputs.image_tag || github.event.inputs.image_tag }}"
          if [ -z "$IMAGE_TAG" ]; then
            IMAGE_TAG="$TARGET_NAMESPACE"
          fi
          
          helm template app "$CHART_DIR" -f "$VALUES_FILE" \
            --set namespace.name="$TARGET_NAMESPACE" \
            --set namespace.create=false \
            --set global.namePrefix="$TARGET_NAMESPACE" \
            --set global.dockerRegistry="$ACR_LOGIN_SERVER" \
            --set global.environment="$IMAGE_TAG" \
            --set global.keyvault.clientId="$KEYVAULT_CLIENT_ID" \
            --set global.keyvault.tenantId="$KEYVAULT_TENANT_ID" \
            --set global.servicebus.namespace="$SERVICEBUS_NAMESPACE" \
            --set global.servicebus.clientId="$SERVICEBUS_CLIENT_ID" \
            --set global.signalr.endpoint="$SIGNALR_ENDPOINT" \
            --set global.signalr.clientId="$SIGNALR_CLIENT_ID" \
            --set global.postgres.endpoint="$POSTGRES_ENDPOINT" \
            --set global.postgres.clientId="$POSTGRES_CLIENT_ID" \
            --set dapr.installComponents=false \
          | grep -n '^kind: Namespace' && { echo "Namespace still rendered"; exit 1; } || echo "OK: no Namespace in chart"

      - name: Setup Azure Workload Identity for managed identity
        if: ${{ steps.setup.outputs.skip_infra_steps == 'false' }}
        run: |
          # Get the OIDC issuer URL from AKS cluster
          AKS_OIDC_ISSUER=$(az aks show \
            --resource-group $AKS_RG \
            --name $AKS_NAME \
            --query "oidcIssuerProfile.issuerUrl" -o tsv)
          echo "OIDC Issuer: $AKS_OIDC_ISSUER"
          
          # Create federated identity credential for cross-RG access
          az identity federated-credential create \
            --name "${TARGET_NAMESPACE}-federated-credential" \
            --identity-name "${TARGET_NAMESPACE}-app-identity" \
            --resource-group "${TARGET_NAMESPACE}-zionet-learning-2025" \
            --issuer "$AKS_OIDC_ISSUER" \
            --subject "system:serviceaccount:${TARGET_NAMESPACE}:${TARGET_NAMESPACE}-workload-identity" \
            --audience "api://AzureADTokenExchange" \
            --only-show-errors || echo "Federated credential already exists or failed"

      - name: Assign Service Bus roles to managed identity
        if: ${{ steps.setup.outputs.skip_infra_steps == 'false' }}
        run: |
          # Get the managed identity details from the resource group
          MANAGED_IDENTITY_PRINCIPAL_ID=$(az identity show \
            --resource-group "${TARGET_NAMESPACE}-zionet-learning-2025" \
            --name "${TARGET_NAMESPACE}-app-identity" \
            --query principalId -o tsv)
          
          SERVICEBUS_NAMESPACE_ID="/subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${TARGET_NAMESPACE}-zionet-learning-2025/providers/Microsoft.ServiceBus/namespaces/${TARGET_NAMESPACE}-servicebus-zionet-learning"
          
          # Assign Service Bus Data Sender role
          az role assignment create \
            --assignee "$MANAGED_IDENTITY_PRINCIPAL_ID" \
            --role "Azure Service Bus Data Sender" \
            --scope "$SERVICEBUS_NAMESPACE_ID" \
            --only-show-errors || echo "Sender role already assigned or failed"
          
          # Assign Service Bus Data Receiver role  
          az role assignment create \
            --assignee "$MANAGED_IDENTITY_PRINCIPAL_ID" \
            --role "Azure Service Bus Data Receiver" \
            --scope "$SERVICEBUS_NAMESPACE_ID" \
            --only-show-errors || echo "Receiver role already assigned or failed"

      - name: Assign SignalR roles to managed identity
        if: ${{ steps.setup.outputs.skip_infra_steps == 'false' }}
        run: |
          # Get the managed identity details from the resource group
          MANAGED_IDENTITY_PRINCIPAL_ID=$(az identity show \
            --resource-group "${TARGET_NAMESPACE}-zionet-learning-2025" \
            --name "${TARGET_NAMESPACE}-app-identity" \
            --query principalId -o tsv)
          
          SIGNALR_RESOURCE_ID="/subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${TARGET_NAMESPACE}-zionet-learning-2025/providers/Microsoft.SignalRService/SignalR/${TARGET_NAMESPACE}-signalr-teachin"
          
          # Assign SignalR App Server role
          az role assignment create \
            --assignee "$MANAGED_IDENTITY_PRINCIPAL_ID" \
            --role "SignalR App Server" \
            --scope "$SIGNALR_RESOURCE_ID" \
            --only-show-errors || echo "SignalR App Server role already assigned or failed"

      - name: Setup PostgreSQL Managed Identity access
        if: ${{ steps.setup.outputs.skip_infra_steps == 'false' }}
        run: |
          # Get the managed identity details from the resource group
          MANAGED_IDENTITY_PRINCIPAL_ID=$(az identity show \
            --resource-group "${TARGET_NAMESPACE}-zionet-learning-2025" \
            --name "${TARGET_NAMESPACE}-app-identity" \
            --query principalId -o tsv)
          
          # Azure AD authentication is already enabled via Portal
          echo "Azure AD authentication is already enabled on PostgreSQL server"
          
          # Wait a moment for the setting to take effect
          sleep 10
          
          # Set the managed identity as PostgreSQL AD administrator using REST API
          echo "Setting ${TARGET_NAMESPACE}-app-identity as PostgreSQL AD admin"
          
          # Try the regular command first
          az postgres flexible-server microsoft-entra-admin create \
            --resource-group "dev-zionet-learning-2025" \
            --server-name "dev-pg-zionet-learning" \
            --display-name "${TARGET_NAMESPACE}-app-identity" \
            --object-id "$MANAGED_IDENTITY_PRINCIPAL_ID" \
            --type User && echo "AD admin set successfully" || {
            
            echo "Regular command failed, trying REST API approach..."
            
            # Get access token
            ACCESS_TOKEN=$(az account get-access-token --query accessToken -o tsv)
            
            # Use REST API to set AD admin with correct endpoint
            curl -X PUT \
              -H "Authorization: Bearer $ACCESS_TOKEN" \
              -H "Content-Type: application/json" \
              -d "{
                \"properties\": {
                  \"administratorType\": \"ActiveDirectory\",
                  \"login\": \"${TARGET_NAMESPACE}-app-identity\",
                  \"sid\": \"$MANAGED_IDENTITY_PRINCIPAL_ID\",
                  \"tenantId\": \"${{ secrets.AZURE_TENANT_ID }}\"
                }
              }" \
              "https://management.azure.com/subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/dev-zionet-learning-2025/providers/Microsoft.DBforPostgreSQL/flexibleServers/dev-pg-zionet-learning/administrators/$MANAGED_IDENTITY_PRINCIPAL_ID?api-version=2022-12-01" \
              || echo "REST API also failed"
          }
            
          # Install psql client for database user creation
          sudo apt-get update -y && sudo apt-get install -y postgresql-client
          
          # Get GitHub runner IP and create temporary firewall rule
          RUNNER_IP=$(curl -s https://api.ipify.org)
          RULE="gha-${GITHUB_RUN_ID}-${GITHUB_RUN_ATTEMPT}"
          az postgres flexible-server firewall-rule create \
            --resource-group "dev-zionet-learning-2025" \
            --name "dev-pg-zionet-learning" \
            --rule-name "$RULE" \
            --start-ip-address "$RUNNER_IP" \
            --end-ip-address "$RUNNER_IP"
            
          # Create managed identity user in the database
          PGPASSWORD="${{ secrets.POSTGRES_PASSWORD }}" psql \
            -h "dev-pg-zionet-learning.postgres.database.azure.com" \
            -U "${{ secrets.POSTGRES_USER }}" \
            -d "appdb-${TARGET_NAMESPACE}" \
            -c "CREATE ROLE \"${TARGET_NAMESPACE}-app-identity@dev-pg-zionet-learning\" WITH LOGIN;" || echo "User may already exist"
            
          PGPASSWORD="${{ secrets.POSTGRES_PASSWORD }}" psql \
            -h "dev-pg-zionet-learning.postgres.database.azure.com" \
            -U "${{ secrets.POSTGRES_USER }}" \
            -d "appdb-${TARGET_NAMESPACE}" \
            -c "GRANT CONNECT ON DATABASE \"appdb-${TARGET_NAMESPACE}\" TO \"${TARGET_NAMESPACE}-app-identity@dev-pg-zionet-learning\";"
            
          PGPASSWORD="${{ secrets.POSTGRES_PASSWORD }}" psql \
            -h "dev-pg-zionet-learning.postgres.database.azure.com" \
            -U "${{ secrets.POSTGRES_USER }}" \
            -d "appdb-${TARGET_NAMESPACE}" \
            -c "GRANT USAGE, CREATE ON SCHEMA public TO \"${TARGET_NAMESPACE}-app-identity@dev-pg-zionet-learning\";"
            
          PGPASSWORD="${{ secrets.POSTGRES_PASSWORD }}" psql \
            -h "dev-pg-zionet-learning.postgres.database.azure.com" \
            -U "${{ secrets.POSTGRES_USER }}" \
            -d "appdb-${TARGET_NAMESPACE}" \
            -c "GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO \"${TARGET_NAMESPACE}-app-identity@dev-pg-zionet-learning\";"
            
          PGPASSWORD="${{ secrets.POSTGRES_PASSWORD }}" psql \
            -h "dev-pg-zionet-learning.postgres.database.azure.com" \
            -U "${{ secrets.POSTGRES_USER }}" \
            -d "appdb-${TARGET_NAMESPACE}" \
            -c "ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES TO \"${TARGET_NAMESPACE}-app-identity@dev-pg-zionet-learning\";"
            
          # Remove temporary firewall rule
          az postgres flexible-server firewall-rule delete \
            --resource-group "dev-zionet-learning-2025" \
            --name "dev-pg-zionet-learning" \
            --rule-name "$RULE" \
            --yes

      - name: Helm upgrade/install app
        run: |
          # Use image_tag if provided, otherwise fall back to TARGET_NAMESPACE
          IMAGE_TAG="${{ inputs.image_tag || github.event.inputs.image_tag }}"
          if [ -z "$IMAGE_TAG" ]; then
            IMAGE_TAG="$TARGET_NAMESPACE"
          fi
          
          helm upgrade --install app "$CHART_DIR" \
            --namespace "$TARGET_NAMESPACE" \
            -f "$VALUES_FILE" \
            --set namespace.name="$TARGET_NAMESPACE" \
            --set namespace.create=false \
            --set global.namePrefix="$TARGET_NAMESPACE" \
            --set global.dockerRegistry="$ACR_LOGIN_SERVER" \
            --set global.environment="$IMAGE_TAG" \
            --set global.keyvault.clientId="$KEYVAULT_CLIENT_ID" \
            --set global.keyvault.tenantId="$KEYVAULT_TENANT_ID" \
            --set global.servicebus.namespace="$SERVICEBUS_NAMESPACE" \
            --set global.servicebus.clientId="$SERVICEBUS_CLIENT_ID" \
            --set global.signalr.endpoint="$SIGNALR_ENDPOINT" \
            --set global.signalr.clientId="$SIGNALR_CLIENT_ID" \
            --set global.postgres.endpoint="$POSTGRES_ENDPOINT" \
            --set global.postgres.clientId="$POSTGRES_CLIENT_ID" \
            --set dapr.stateStore.redis.redisDB=$REDIS_DATABASE_INDEX \
            --set dapr.installComponents=false

      - name: Diagnostics (on failure)
        if: failure()
        run: |
          ns="$TARGET_NAMESPACE"
          kubectl -n "$ns" get all
          kubectl -n "$ns" get events --sort-by=.lastTimestamp | tail -n 200 || true
          for p in $(kubectl -n "$ns" get pods -o name); do
            echo "## $p"
            kubectl -n "$ns" describe "$p" || true
            kubectl -n "$ns" logs "$p" --all-containers --tail=200 || true
          done
